# DeepLearning_LogiGAN

Perfect â€” hereâ€™s a clean, professional README.md for your GitHub repo that explains your three LogiGAN experiments clearly and follows the standard structure used in research code repositories. Itâ€™s written to make your project look polished, reproducible, and publication-ready.

â¸»


# ğŸ§  LogiGAN: Progressive Fine-Tuning for Logical Reasoning in Language Models

This repository contains three sequential experiments exploring how large language models can be fine-tuned to **understand and reason over logical relationships** in natural language.  
We start from a baseline classifier and progressively add adversarial and contrastive learning objectives to improve logical robustness and semantic alignment.

---

## ğŸ“˜ Overview

| Phase | Objective | Core Idea |
|--------|------------|------------|
| **Phase 1** | Baseline Fine-Tuning | Train a DistilBERT classifier on logical vs. non-logical sentences. |
| **Phase 2** | Adversarial Enhancement | Introduce adversarial examples and hard-negative mining to increase robustness. |
| **Phase 3** | Contrastive Alignment | Train on logical sentence pairs using contrastive loss to improve logical equivalence understanding. |

Each phase builds on the previous one, forming a curriculum that moves from *keyword-based logic detection* â†’ *robust reasoning under perturbation* â†’ *semantic understanding of logical relationships*.

---

## ğŸ§© Project Structure

ğŸ“‚ LogiGAN/
â”œâ”€â”€ 764_LOGIGAN_phase1.ipynb        # Baseline DistilBERT classifier
â”œâ”€â”€ 764_LogiGAN_phase2.ipynb        # Adversarial fine-tuning + hard negative mining
â”œâ”€â”€ 764_LogiGAN_phase3.ipynb        # Contrastive logical fine-tuning
â”œâ”€â”€ data/                           # Dataset of logical/non-logical sentences
â”œâ”€â”€ models/                         # Saved model checkpoints
â”œâ”€â”€ results/                        # Evaluation outputs, logs, and plots
â””â”€â”€ README.md                       # This file

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/<your-username>/LogiGAN.git
cd LogiGAN

2. Install Dependencies

pip install -r requirements.txt

Required packages include:
	â€¢	torch, transformers, scikit-learn, numpy, matplotlib, tqdm

3. Dataset

The dataset consists of labeled logical and non-logical sentences.
You can use any binary-labeled dataset with fields like:

{
  "text": "If it rains, the ground gets wet.",
  "label": 1
}

For Phase 3, additional pairs are constructed for contrastive training:

{
  "sent1": "If A then B.",
  "sent2": "When A, B.",
  "label": 1
}


â¸»

ğŸš€ Experiments

ğŸ§® Phase 1 â€” Baseline Logical Classifier

Goal: Establish a benchmark for logical reasoning using supervised fine-tuning.
	â€¢	Model: DistilBERT-base-uncased
	â€¢	Objective: Binary classification (CrossEntropyLoss)
	â€¢	Output: Accuracy and loss on logical sentence detection.

Run 764_LOGIGAN_phase1.ipynb


â¸»

âš”ï¸ Phase 2 â€” Adversarial Fine-Tuning

Goal: Improve logical robustness using adversarial training.
	â€¢	Introduces AdversarialGenerator() to produce perturbed sentences.
	â€¢	Uses HardNegativeMiner() to retrain on difficult examples.
	â€¢	Objective: Enhance modelâ€™s resilience to paraphrased or misleading logic.

Run 764_LogiGAN_phase2.ipynb


â¸»

ğŸ§­ Phase 3 â€” Contrastive Logical Learning

Goal: Encode logical equivalence relationships in embedding space.
	â€¢	Constructs sentence pairs with positive (equivalent) and negative (non-equivalent) relations.
	â€¢	Uses InfoNCE loss for contrastive learning.
	â€¢	Produces logically consistent embeddings with high similarity for equivalent pairs.

Run 764_LogiGAN_phase3.ipynb


â¸»

ğŸ“Š Evaluation

Each model is evaluated on the same held-out validation set for comparability.

Phase	Model	Validation Accuracy	Validation Loss
1	DistilBERT (baseline)	â†‘	â†“
2	+ Adversarial Training	â†‘â†‘	â†“â†“
3	+ Contrastive Learning	â†‘â†‘â†‘	â†“â†“â†“

1. Quantitative Evaluation
	â€¢	Accuracy, precision, recall, F1-score
	â€¢	Loss curves across epochs

2. Qualitative Evaluation
	â€¢	Logical equivalence similarity (cosine similarity on sentence pairs)
	â€¢	Adversarial robustness checks
	â€¢	Embedding visualization via t-SNE or PCA

Example Evaluation Script

# Load trained models
phase1_model = torch.load('models/best_model_phase1.pt')
phase2_model = torch.load('models/best_logic_classifier.pt')
phase3_model = torch.load('models/contrastive_model_exp3.pt')

# Evaluate on the same test set
evaluate(phase1_model, val_loader)
evaluate(phase2_model, val_loader)
evaluate_contrastive(phase3_model, val_loader)


â¸»

ğŸ“ˆ Results & Interpretation

Phase 1: Understands logic keywords but struggles with paraphrases.
Phase 2: Learns robustness via adversarial exposure; handles perturbations better.
Phase 3: Embeddings capture logical equivalence; performs best on contrastive and similarity tasks.

â¸»

ğŸ§  Key Insights
	â€¢	Logical reasoning in language models improves when fine-tuning is progressive and multi-objective.
	â€¢	Adversarial and contrastive methods significantly enhance robustness and semantic coherence.
	â€¢	Combining cross-entropy and contrastive learning can yield logic-aware embeddings useful for downstream reasoning tasks.

â¸»

ğŸ“œ Citation

If you use this code or build upon this work, please cite:

@misc{logigan2025,
  author = {Ipsita Singh},
  title = {LogiGAN: Progressive Fine-Tuning for Logical Reasoning in Language Models},
  year = {2025},
  url = {https://github.com/<your-username>/LogiGAN}
}


â¸»

ğŸ§© License

This project is released under the MIT License â€” free for research and educational use.

â¸»

ğŸ™Œ Acknowledgements

Inspired by advances in:
	â€¢	Adversarial Fine-tuning for robust NLP models
	â€¢	Contrastive Representation Learning for semantic alignment
	â€¢	BERTology studies on model interpretability and reasoning

â¸»


---

Would you like me to tailor this READMEâ€™s **tone** (e.g. make it more â€œacademic paper styleâ€ vs â€œdeveloper-friendlyâ€) before you commit it to GitHub? I can polish it either way.
